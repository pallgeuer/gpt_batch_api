Setup
-----

- Create conda environment:
	conda create -n gpt_batch_api python=3.12
	conda activate gpt_batch_api
	conda install -c conda-forge filelock pillow 'pydantic>=2' pytest requests wandb
	pip install openai tiktoken
	pip check

- Wandb login:
	wandb login

Run Commands
------------

- General:
	cd /path/to/gpt_batch_api/..  # <-- NOTE: Parent directory of gpt_batch_api
	conda activate gpt_batch_api
	export OPENAI_API_KEY=sk-...  # <-- NOTE: Replace with actual OpenAI API key
	export WANDB_API_KEY=...  # <-- NOTE: Replace with actual Wandb API key

- General configuration:
	MODELARGS=(--model gpt-4o-mini-2024-07-18 --cost_input_direct_mtoken 0.150 --cost_input_cached_mtoken 0.075 --cost_input_batch_mtoken 0.075 --cost_output_direct_mtoken 0.600 --cost_output_batch_mtoken 0.300)

- Run the available pytests:
	Command:
		pytest -v gpt_batch_api/utils_test.py
	Verify:
		Verify that all tests passed

- Test the token counting class TokenEstimator:
	Command:
		python -m gpt_batch_api.tokens_test
	Verify:
		Verify that all predicted token totals are equal or close to the actual required number of tokens
		OpenAI changes things from time to time, so TokenEstimator may occasionally require updates in order to be accurate, especially for new models

- Demo the TaskManager class:
	Command:
		python -m gpt_batch_api.task_manager_demo --help
		python -m gpt_batch_api.task_manager_demo --task char_codes "${MODELARGS[@]}" --assumed_completion_ratio 0.25
		python -m gpt_batch_api.task_manager_demo --task utterance_emotion "${MODELARGS[@]}" --assumed_completion_ratio 0.35
	Args:
		Refer to --help
	Output:
		gpt_batch_api/tasks/char_codes_*
		gpt_batch_api/tasks/utterance_emotion_*
	Verify:
		Verify that the final data output file(s) contain reasonable and complete data (e.g. gpt_batch_api/tasks/char_codes_output*, gpt_batch_api/tasks/utterance_emotion_output*)

- Safe steps when trying out a new custom task:
	Notes:
		It is assumed for these commands that the custom task manager has been wrapped into a script that uses argparse (including also --model) to configure the task manager and GPT requester.
		If hydra or a direct programmatic interface is being used instead for the configuration parameters, then the commands below can be easily adjusted to the appropriate form.
		The generic command is 'python ...', which could for example be 'python -m gpt_batch_api.task_manager_demo --task char_codes'.
	List all available command line arguments:
		python ... --help
	Show 10 verbose examples of generated requests without actually executing them:
		python ... "${MODELARGS[@]}" --force_direct --direct_verbose always --max_session_requests 10 --dryrun
	Show 10 verbose examples of generated requests and responses using the direct API:
		python ... "${MODELARGS[@]}" --force_direct --direct_verbose always --max_session_requests 10
	Execute 100 requests using the direct API, and show those examples verbosely that had a warning or error:
		python ... "${MODELARGS[@]}" --force_direct --direct_verbose warn --max_session_requests 100
	Execute 250 requests using the batch API:
		python ... "${MODELARGS[@]}" --max_batch_requests 250 --max_session_requests 250
		# <-- Based on the results, estimate suitable values for the request max_completion_tokens, and based on that a suitable value for assumed_completion_ratio, e.g. 0.3
	Execute 1 USD worth of requests using the batch API (or 1 of whatever currency/unit MODELARGS uses):
		python ... "${MODELARGS[@]}" --assumed_completion_ratio 0.3 --only_process  # <-- If there are any unfinished batches busy on the remote (we don't want to unnecessarily wipe them)
		python ... --wipe_requests "${MODELARGS[@]}" --assumed_completion_ratio 0.3 --max_batch_cost 1.00 --max_session_cost 1.00
		# <-- Calculate finetuned assumed_completion_ratio value if required, e.g. 0.32
	Reset the entire task to scratch and throw away any results obtained so far:
		python ... --wipe_task --no_run "${MODELARGS[@]}" --assumed_completion_ratio 0.3
	Run the task normally to completion, respecting a batch queue limit of 5,000,000 tokens (= 5000 ktokens) at a time (refer to the OpenAI tier rate limits):
		python ... "${MODELARGS[@]}" --assumed_completion_ratio 0.3 --max_remote_ktokens 5000
		# The above command can be interrupted with Ctrl+C and restarted at any time, and it will safely and robustly just pick up where it left off without losing anything (assuming the custom task has been correctly and revertibly implemented like described in the documentation, and demonstrated in task_manager_demo.py)
	Get the current status of a task without actually executing task steps:
		python ... "${MODELARGS[@]}" --assumed_completion_ratio 0.3 --max_remote_ktokens 5000 --no_run

- TODO: Debugging, apply changes made to request generation and/or recover from any errors, bad requests or early exits due to failures, or such:
         - --dryrun => Prevent any API calls and changes to saved disk state, and just show what would be done
         - --max_remote_ktokens 90 (dependent ones?) => OpenAI tiers limit how many tokens can be pending in the batch queue at any one time. This can be configured like this
         - --max_batch_requests 50 => Limit the number of requests per batch (num batches/num requests/num tokens/cost/MB size can be limited for each batch, the remote server, each session, or the entire task, as appropriate)
         - --max_remote_batches 0 --max_unpushed_batches 3 => Generate local batches without letting them be pushed
         - --max_retries 5 => Adjust how often a request can be retried before it is declared as failed
         - --min_pass_ratio 0.8 => At least what ratio of the requests in a batch need to be successful in order for the batch to 'pass' (too many non-passed batches lead to an error and aborting for safety, see --max_pass_failures 2)
         - --process_failed_batches 2 [--retry_fatal_requests] => If there are failed batches then the task aborts for safety (as manual intervention/code changes/sanity checking is probably required) => This parameter can be used to allow/force up to a certain number of failed batches to be processed anyway, thereby allowing the task to proceed. If supplying --retry_fatal_requests then requests that received fatal errors will be allowed to be retried (normally they are not as fatal errors are ones where it is not expected that a retry has a chance of resolving the issue)
         - python ... --only_process => Allow all pushed batches to complete and be processed without generating, commiting or pushing any new requests
         - --reinit_meta => Force the task metadata to be updated (usually task metadata is only captured once when the task is created/initialised) => E.g. Change model, temperature, hyperparameters for parsing, etc (you must ensure that your task implementation can deal with whatever of these parameters you change changing)
         - --wipe_requests => (only_process first) => Wipe all ongoing requests (e.g. useful if you changed the request generation and want to reconstruct all the requests in the queue/local batches/etc
         - --wipe_failed => (only_process first) => Wipe all ongoing requests and ant failed samples, allowing them to be attempted again (with the full number of retries available again)
         - --wipe_task => Wipe entire task and start completely from scratch
