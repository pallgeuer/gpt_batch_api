Setup
-----

- Create conda environment:
	conda create -n gpt_batch_api python=3.12
	conda activate gpt_batch_api
	conda install -c conda-forge filelock pillow 'pydantic>=2' pytest requests wandb
	pip install openai tiktoken
	pip check

- Wandb login:
	wandb login

Run Commands
------------

- General:
	cd /path/to/gpt_batch_api/..
	conda activate gpt_batch_api
	export OPENAI_API_KEY=sk-...  # <-- NOTE: Replace with actual OpenAI API key
	export WANDB_API_KEY=...  # <-- NOTE: Replace with actual Wandb API key

- Test the token counting class TokenEstimator:
	Command:
		python -m gpt_batch_api.tokens_test
	Verify:
		Verify that all predicted token totals are equal or close to the actual required number of tokens

- Demo the TaskManager class:
	Command:
		python -m gpt_batch_api.task_manager_demo --task char_codes
	Args:
		Refer to --help
	Output:
		gpt_batch_api/tasks/char_codes_*
	Verify:
		Verify that the final data output file(s) contain reasonable and complete data (e.g. gpt_batch_api/tasks/char_codes_output*)

TODO: MODELARGS=(...) --> Use "${MODELARGS[@]}"
TODO: Pytests
TODO: Customise model and its costing => Default command for char_codes mis-costs!
TODO: only_process=True
TODO: Process failed batches and other recovery methods
TODO: Wipe requests / failed / task
